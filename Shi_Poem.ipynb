{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Song Poem.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMAcxN3LG06R7j8fUQRg5jv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/swk16/Coding-3/blob/main/Shi_Poem.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "2uL9Bq2f2odR"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "import sys\n",
        "import os\n",
        "import re\n",
        "import numpy             as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle           "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "filename = '诗经.txt'"
      ],
      "metadata": {
        "id": "SXGPRNdI2qP3"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f = open(filename, 'rb')\n",
        "for i in range(0, 1000):\n",
        "    line = str(f.readline(), \"cp936\")\n",
        "    print (len(line))\n",
        "   \n",
        "f.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lyUKSyAh2vAL",
        "outputId": "0da0b973-b82b-49c8-be03-9f4f7fc21e42"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2\n",
            "10\n",
            "2\n",
            "7\n",
            "2\n",
            "2\n",
            "4\n",
            "2\n",
            "22\n",
            "2\n",
            "22\n",
            "2\n",
            "22\n",
            "2\n",
            "22\n",
            "2\n",
            "22\n",
            "2\n",
            "4\n",
            "2\n",
            "17\n",
            "2\n",
            "17\n",
            "2\n",
            "17\n",
            "2\n",
            "17\n",
            "2\n",
            "17\n",
            "2\n",
            "17\n",
            "2\n",
            "4\n",
            "2\n",
            "22\n",
            "2\n",
            "25\n",
            "2\n",
            "25\n",
            "2\n",
            "22\n",
            "2\n",
            "4\n",
            "2\n",
            "22\n",
            "2\n",
            "22\n",
            "2\n",
            "22\n",
            "2\n",
            "4\n",
            "2\n",
            "19\n",
            "2\n",
            "19\n",
            "2\n",
            "19\n",
            "2\n",
            "4\n",
            "2\n",
            "22\n",
            "2\n",
            "22\n",
            "2\n",
            "22\n",
            "2\n",
            "4\n",
            "2\n",
            "22\n",
            "2\n",
            "22\n",
            "2\n",
            "22\n",
            "2\n",
            "4\n",
            "2\n",
            "22\n",
            "2\n",
            "22\n",
            "2\n",
            "22\n",
            "2\n",
            "4\n",
            "2\n",
            "42\n",
            "2\n",
            "42\n",
            "2\n",
            "42\n",
            "2\n",
            "4\n",
            "2\n",
            "22\n",
            "2\n",
            "22\n",
            "2\n",
            "22\n",
            "2\n",
            "5\n",
            "2\n",
            "44\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "7\n",
            "2\n",
            "2\n",
            "4\n",
            "2\n",
            "22\n",
            "2\n",
            "22\n",
            "2\n",
            "22\n",
            "2\n",
            "4\n",
            "2\n",
            "22\n",
            "2\n",
            "22\n",
            "2\n",
            "22\n",
            "2\n",
            "4\n",
            "2\n",
            "37\n",
            "2\n",
            "37\n",
            "2\n",
            "37\n",
            "2\n",
            "4\n",
            "2\n",
            "22\n",
            "2\n",
            "22\n",
            "2\n",
            "22\n",
            "2\n",
            "4\n",
            "2\n",
            "17\n",
            "2\n",
            "17\n",
            "2\n",
            "17\n",
            "2\n",
            "4\n",
            "2\n",
            "17\n",
            "2\n",
            "36\n",
            "2\n",
            "36\n",
            "2\n",
            "4\n",
            "2\n",
            "22\n",
            "2\n",
            "22\n",
            "2\n",
            "22\n",
            "2\n",
            "5\n",
            "2\n",
            "32\n",
            "2\n",
            "32\n",
            "2\n",
            "32\n",
            "2\n",
            "5\n",
            "2\n",
            "21\n",
            "2\n",
            "21\n",
            "2\n",
            "21\n",
            "2\n",
            "4\n",
            "2\n",
            "27\n",
            "2\n",
            "27\n",
            "2\n",
            "5\n",
            "2\n",
            "23\n",
            "2\n",
            "23\n",
            "2\n",
            "23\n",
            "2\n",
            "6\n",
            "2\n",
            "22\n",
            "2\n",
            "22\n",
            "2\n",
            "20\n",
            "2\n",
            "6\n",
            "2\n",
            "22\n",
            "2\n",
            "22\n",
            "2\n",
            "22\n",
            "2\n",
            "4\n",
            "2\n",
            "18\n",
            "2\n",
            "18\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "7\n",
            "2\n",
            "2\n",
            "4\n",
            "2\n",
            "32\n",
            "2\n",
            "32\n",
            "2\n",
            "32\n",
            "2\n",
            "32\n",
            "2\n",
            "32\n",
            "2\n",
            "4\n",
            "2\n",
            "22\n",
            "2\n",
            "22\n",
            "2\n",
            "22\n",
            "2\n",
            "22\n",
            "2\n",
            "4\n",
            "2\n",
            "32\n",
            "2\n",
            "32\n",
            "2\n",
            "32\n",
            "2\n",
            "32\n",
            "2\n",
            "4\n",
            "2\n",
            "33\n",
            "2\n",
            "33\n",
            "2\n",
            "33\n",
            "2\n",
            "32\n",
            "2\n",
            "4\n",
            "2\n",
            "22\n",
            "2\n",
            "22\n",
            "2\n",
            "22\n",
            "2\n",
            "22\n",
            "2\n",
            "4\n",
            "2\n",
            "22\n",
            "2\n",
            "22\n",
            "2\n",
            "22\n",
            "2\n",
            "22\n",
            "2\n",
            "22\n",
            "2\n",
            "4\n",
            "2\n",
            "22\n",
            "2\n",
            "22\n",
            "2\n",
            "21\n",
            "2\n",
            "22\n",
            "2\n",
            "4\n",
            "2\n",
            "22\n",
            "2\n",
            "22\n",
            "2\n",
            "22\n",
            "2\n",
            "22\n",
            "2\n",
            "6\n",
            "2\n",
            "20\n",
            "2\n",
            "24\n",
            "2\n",
            "22\n",
            "2\n",
            "22\n",
            "2\n",
            "4\n",
            "2\n",
            "42\n",
            "2\n",
            "42\n",
            "2\n",
            "42\n",
            "2\n",
            "42\n",
            "2\n",
            "44\n",
            "2\n",
            "42\n",
            "2\n",
            "4\n",
            "2\n",
            "23\n",
            "2\n",
            "23\n",
            "2\n",
            "4\n",
            "2\n",
            "24\n",
            "2\n",
            "22\n",
            "2\n",
            "22\n",
            "2\n",
            "22\n",
            "2\n",
            "4\n",
            "2\n",
            "22\n",
            "2\n",
            "22\n",
            "2\n",
            "22\n",
            "2\n",
            "31\n",
            "2\n",
            "4\n",
            "2\n",
            "32\n",
            "2\n",
            "33\n",
            "2\n",
            "32\n",
            "2\n",
            "32\n",
            "2\n",
            "4\n",
            "2\n",
            "36\n",
            "2\n",
            "40\n",
            "2\n",
            "40\n",
            "2\n",
            "4\n",
            "2\n",
            "32\n",
            "2\n",
            "32\n",
            "2\n",
            "32\n",
            "2\n",
            "4\n",
            "2\n",
            "23\n",
            "2\n",
            "22\n",
            "2\n",
            "23\n",
            "2\n",
            "4\n",
            "2\n",
            "23\n",
            "2\n",
            "22\n",
            "2\n",
            "22\n",
            "2\n",
            "6\n",
            "2\n",
            "22\n",
            "2\n",
            "22\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "7\n",
            "2\n",
            "2\n",
            "4\n",
            "2\n",
            "38\n",
            "2\n",
            "38\n",
            "2\n",
            "5\n",
            "2\n",
            "31\n",
            "2\n",
            "31\n",
            "2\n",
            "31\n",
            "2\n",
            "6\n",
            "2\n",
            "37\n",
            "2\n",
            "50\n",
            "2\n",
            "44\n",
            "2\n",
            "4\n",
            "2\n",
            "42\n",
            "2\n",
            "42\n",
            "2\n",
            "42\n",
            "2\n",
            "6\n",
            "2\n",
            "22\n",
            "2\n",
            "22\n",
            "2\n",
            "6\n",
            "2\n",
            "25\n",
            "3\n",
            "3\n",
            "2\n",
            "37\n",
            "2\n",
            "37\n",
            "2\n",
            "4\n",
            "2\n",
            "23\n",
            "2\n",
            "23\n",
            "2\n",
            "23\n",
            "2\n",
            "4\n",
            "2\n",
            "22\n",
            "2\n",
            "22\n",
            "2\n",
            "22\n",
            "2\n",
            "4\n",
            "2\n",
            "32\n",
            "2\n",
            "32\n",
            "2\n",
            "32\n",
            "2\n",
            "4\n",
            "2\n",
            "32\n",
            "2\n",
            "42\n",
            "2\n",
            "32\n",
            "2\n",
            "43\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "7\n",
            "2\n",
            "2\n",
            "4\n",
            "2\n",
            "48\n",
            "2\n",
            "49\n",
            "2\n",
            "47\n",
            "2\n",
            "4\n",
            "2\n",
            "22\n",
            "2\n",
            "22\n",
            "2\n",
            "22\n",
            "2\n",
            "4\n",
            "2\n",
            "37\n",
            "2\n",
            "37\n",
            "2\n",
            "37\n",
            "2\n",
            "37\n",
            "2\n",
            "3\n",
            "2\n",
            "52\n",
            "2\n",
            "52\n",
            "2\n",
            "52\n",
            "2\n",
            "52\n",
            "2\n",
            "53\n",
            "2\n",
            "52\n",
            "2\n",
            "4\n",
            "2\n",
            "22\n",
            "2\n",
            "23\n",
            "2\n",
            "22\n",
            "2\n",
            "22\n",
            "2\n",
            "4\n",
            "2\n",
            "33\n",
            "2\n",
            "32\n",
            "2\n",
            "4\n",
            "2\n",
            "22\n",
            "2\n",
            "22\n",
            "2\n",
            "4\n",
            "2\n",
            "22\n",
            "2\n",
            "22\n",
            "2\n",
            "22\n",
            "2\n",
            "22\n",
            "2\n",
            "4\n",
            "2\n",
            "22\n",
            "2\n",
            "22\n",
            "2\n",
            "22\n",
            "2\n",
            "4\n",
            "2\n",
            "24\n",
            "2\n",
            "24\n",
            "2\n",
            "24\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "7\n",
            "2\n",
            "2\n",
            "4\n",
            "2\n",
            "51\n",
            "2\n",
            "51\n",
            "2\n",
            "51\n",
            "2\n",
            "6\n",
            "2\n",
            "42\n",
            "2\n",
            "42\n",
            "2\n",
            "6\n",
            "2\n",
            "22\n",
            "2\n",
            "22\n",
            "2\n",
            "5\n",
            "2\n",
            "34\n",
            "2\n",
            "34\n",
            "2\n",
            "34\n",
            "2\n",
            "6\n",
            "2\n",
            "33\n",
            "2\n",
            "33\n",
            "2\n",
            "31\n",
            "2\n",
            "4\n",
            "2\n",
            "35\n",
            "2\n",
            "36\n",
            "2\n",
            "36\n",
            "2\n",
            "4\n",
            "2\n",
            "32\n",
            "2\n",
            "32\n",
            "2\n",
            "32\n",
            "2\n",
            "4\n",
            "2\n",
            "17\n",
            "2\n",
            "17\n",
            "2\n",
            "17\n",
            "2\n",
            "4\n",
            "2\n",
            "22\n",
            "2\n",
            "22\n",
            "2\n",
            "22\n",
            "2\n",
            "6\n",
            "2\n",
            "23\n",
            "2\n",
            "22\n",
            "2\n",
            "22\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "7\n",
            "2\n",
            "2\n",
            "4\n",
            "2\n",
            "29\n",
            "2\n",
            "29\n",
            "2\n",
            "29\n",
            "2\n",
            "5\n",
            "2\n",
            "42\n",
            "2\n",
            "42\n",
            "2\n",
            "43\n",
            "2\n",
            "5\n",
            "2\n",
            "26\n",
            "2\n",
            "26\n",
            "2\n",
            "26\n",
            "2\n",
            "6\n",
            "2\n",
            "50\n",
            "2\n",
            "49\n",
            "2\n",
            "49\n",
            "2\n",
            "4\n",
            "2\n",
            "23\n",
            "2\n",
            "23\n",
            "2\n",
            "22\n",
            "2\n",
            "4\n",
            "2\n",
            "22\n",
            "2\n",
            "22\n",
            "2\n",
            "22\n",
            "2\n",
            "5\n",
            "2\n",
            "24\n",
            "2\n",
            "24\n",
            "2\n",
            "6\n",
            "2\n",
            "32\n",
            "2\n",
            "32\n",
            "2\n",
            "38\n",
            "2\n",
            "6\n",
            "2\n",
            "32\n",
            "2\n",
            "32\n",
            "2\n",
            "6\n",
            "2\n",
            "22\n",
            "2\n",
            "22\n",
            "2\n",
            "4\n",
            "2\n",
            "22\n",
            "2\n",
            "22\n",
            "2\n",
            "4\n",
            "2\n",
            "25\n",
            "2\n",
            "25\n",
            "2\n",
            "4\n",
            "2\n",
            "29\n",
            "2\n",
            "29\n",
            "2\n",
            "3\n",
            "2\n",
            "19\n",
            "2\n",
            "19\n",
            "2\n",
            "22\n",
            "2\n",
            "22\n",
            "2\n",
            "6\n",
            "2\n",
            "22\n",
            "2\n",
            "22\n",
            "2\n",
            "4\n",
            "2\n",
            "22\n",
            "2\n",
            "22\n",
            "2\n",
            "22\n",
            "2\n",
            "4\n",
            "2\n",
            "23\n",
            "2\n",
            "22\n",
            "2\n",
            "22\n",
            "2\n",
            "5\n",
            "2\n",
            "32\n",
            "2\n",
            "32\n",
            "2\n",
            "6\n",
            "2\n",
            "32\n",
            "2\n",
            "32\n",
            "2\n",
            "6\n",
            "2\n",
            "32\n",
            "2\n",
            "32\n",
            "2\n",
            "4\n",
            "2\n",
            "60\n",
            "2\n",
            "60\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "7\n",
            "2\n",
            "2\n",
            "4\n",
            "2\n",
            "22\n",
            "2\n",
            "23\n",
            "2\n",
            "24\n",
            "2\n",
            "3\n",
            "2\n",
            "29\n",
            "2\n",
            "29\n",
            "2\n",
            "29\n",
            "2\n",
            "3\n",
            "2\n",
            "24\n",
            "2\n",
            "24\n",
            "2\n",
            "24\n",
            "2\n",
            "6\n",
            "2\n",
            "28\n",
            "2\n",
            "28\n",
            "2\n",
            "6\n",
            "2\n",
            "22\n",
            "2\n",
            "22\n",
            "2\n",
            "22\n",
            "2\n",
            "4\n",
            "2\n",
            "32\n",
            "2\n",
            "32\n",
            "2\n",
            "34\n",
            "2\n",
            "34\n",
            "2\n",
            "4\n",
            "2\n",
            "22\n",
            "2\n",
            "22\n",
            "2\n",
            "22\n",
            "2\n",
            "4\n",
            "2\n",
            "12\n",
            "2\n",
            "12\n",
            "2\n",
            "12\n",
            "2\n",
            "4\n",
            "2\n",
            "22\n",
            "2\n",
            "22\n",
            "2\n",
            "22\n",
            "2\n",
            "4\n",
            "2\n",
            "22\n",
            "2\n",
            "22\n",
            "2\n",
            "22\n",
            "2\n",
            "22\n",
            "2\n",
            "4\n",
            "2\n",
            "32\n",
            "2\n",
            "32\n",
            "2\n",
            "32\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "7\n",
            "2\n",
            "2\n",
            "4\n",
            "2\n",
            "32\n",
            "2\n",
            "27\n",
            "2\n",
            "5\n",
            "2\n",
            "31\n",
            "2\n",
            "31\n",
            "2\n",
            "31\n",
            "2\n",
            "5\n",
            "2\n",
            "32\n",
            "2\n",
            "32\n",
            "2\n",
            "33\n",
            "2\n",
            "32\n",
            "2\n",
            "4\n",
            "2\n",
            "38\n",
            "2\n",
            "38\n",
            "2\n",
            "38\n",
            "2\n",
            "6\n",
            "2\n",
            "20\n",
            "2\n",
            "20\n",
            "2\n",
            "4\n",
            "2\n",
            "35\n",
            "2\n",
            "26\n",
            "2\n",
            "35\n",
            "2\n",
            "26\n",
            "2\n",
            "35\n",
            "2\n",
            "26\n",
            "2\n",
            "4\n",
            "2\n",
            "42\n",
            "2\n",
            "42\n",
            "2\n",
            "42\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "7\n",
            "2\n",
            "2\n",
            "4\n",
            "2\n",
            "42\n",
            "2\n",
            "42\n",
            "2\n",
            "42\n",
            "2\n",
            "5\n",
            "2\n",
            "40\n",
            "2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test some special characters\n",
        "special = [u'\\u3010', u'\\u3011'] ##'【' & '】'\n",
        "f = open(filename, 'rb')\n",
        "for i in range(0, 5):\n",
        "    line = str(f.readline(), \"cp936\")\n",
        "f.close()\n"
      ],
      "metadata": {
        "id": "DwZcCXZn2xtJ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def add_lines(old_line, line, poems):\n",
        "    #print line\n",
        "    if len(line) < 12 or re.search(u'\\u3010', line) is not None:\n",
        "        '''If this line is blank or title'''\n",
        "        old_line = ''\n",
        "    elif old_line == '':\n",
        "        '''If start a new line'''\n",
        "        poems.append(line[0:-2])\n",
        "        old_line = line\n",
        "    else:\n",
        "        '''If continuing to last poem'''\n",
        "        poems[-1] = poems[-1]+line[0:-2]\n",
        "        old_line = line\n",
        "    return poems, old_line"
      ],
      "metadata": {
        "id": "Z5K_Thw325fn"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print (\"Reading txt file...\")\n",
        "poems = []\n",
        "old_line = ''\n",
        "with open(filename, 'rb') as f:\n",
        "    while True:\n",
        "        try:\n",
        "            line = str(f.readline(), \"cp936\")\n",
        "        except:\n",
        "            continue\n",
        "            \n",
        "        if not line:\n",
        "            break\n",
        "            \n",
        "        poems, old_line = add_lines(old_line, line, poems)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3K-LDdoF28K7",
        "outputId": "ceb9c79a-88fa-4778-8dd7-3430017ee453"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading txt file...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Amount is\",len(poems))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HVW0333r2-hF",
        "outputId": "755f14c2-6d31-4c0b-e762-84c7ae8b7420"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Amount is 3251\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(0, 10):\n",
        "    print (poems[i])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n6X9YOYF3BE5",
        "outputId": "f0d5907d-413c-41e4-cf16-0637509363e7"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "关关雎鸠，在河之洲。窈窕淑女，君子好逑。\n",
            "参差荇菜，左右流之。窈窕淑女，寤寐求之。\n",
            "求之不得，寤寐思服。悠哉悠哉，辗转反侧。\n",
            "参差荇菜，左右采之。窈窕淑女，琴瑟友之。\n",
            "参差荇菜，左右芼之。窈窕淑女，钟鼓乐之。\n",
            "葛之覃兮，施于中谷，维叶萋萋。\n",
            "黄鸟于飞，集于灌木，其鸣喈喈。\n",
            "葛之覃兮，施于中谷，维叶莫莫。\n",
            "是刈是濩，为絺为绤，服之无斁。\n",
            "言告师氏，言告言归。薄污我私，\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize(poem):\n",
        "    # poem_tokenize = [u'poem_start']\n",
        "    poem_tokenize = []\n",
        "    poem_tokenize.extend([poem[i] for i in range(0, len(poem))])\n",
        "    # poem_tokenize.append(u'poem_end')\n",
        "    return poem_tokenize\n",
        "poems_tokenize = [tokenize(poems[i]) for i in range(0, len(poems))]\n",
        "print (poems_tokenize[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yk9VLKtf3D7c",
        "outputId": "4c18b70a-ac64-47ad-f220-3af1501feb11"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['关', '关', '雎', '鸠', '，', '在', '河', '之', '洲', '。', '窈', '窕', '淑', '女', '，', '君', '子', '好', '逑', '。']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "poems[0]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "vZcOYQH23GLE",
        "outputId": "058d7784-3611-4041-ee4d-1640ee6e243a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'关关雎鸠，在河之洲。窈窕淑女，君子好逑。'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print (len(poems[0]))\n",
        "poems[0][3]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "kWO5GaL_3V76",
        "outputId": "c50b71b2-b14d-4f5e-a9ad-02d053898d09"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'鸠'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create tokenized poems\n",
        "def tokenize(poem):\n",
        "    # poem_tokenize = [u'poem_start']\n",
        "    poem_tokenize = []\n",
        "    poem_tokenize.extend([poem[i] for i in range(0, len(poem))])\n",
        "    # poem_tokenize.append(u'poem_end')\n",
        "    return poem_tokenize\n",
        "poems_tokenize = [tokenize(poems[i]) for i in range(0, len(poems))]\n",
        "print (poems_tokenize[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BEtaJRMK3kaa",
        "outputId": "541dd128-5542-4bb2-fa92-8f2135542580"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['关', '关', '雎', '鸠', '，', '在', '河', '之', '洲', '。', '窈', '窕', '淑', '女', '，', '君', '子', '好', '逑', '。']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check unique characters\n",
        "len(np.unique(poems_tokenize))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ftbHSMm3oLI",
        "outputId": "f016ec4b-1ee5-4a4e-de28-635b180956f6"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/arraysetops.py:270: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  ar = np.asanyarray(ar)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1234"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check number of characters in total\n",
        "sum([len(poems_tokenize[i]) for i in range(0, len(poems_tokenize))])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g86UK5LO3syW",
        "outputId": "72ffdeee-86f7-452d-a554-7dc466d7eda3"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "102713"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot words frequency\n",
        "tokens = [item for sublist in poems_tokenize for item in sublist]\n",
        "#lambda poems_tokenize: [item for sublist in poems_tokenize for item in sublist]\n",
        "unique_token = np.unique(tokens)\n",
        "n_unique_token = len(unique_token)\n",
        "tokens_count = []\n",
        "for i in range(0, n_unique_token):\n",
        "    tokens_count.append(tokens.count(unique_token[i]))\n",
        "#tokens.count(unique_token[0])"
      ],
      "metadata": {
        "id": "4OSGXKA83vbr"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print ('median counts: %d ' % np.median(tokens_count))\n",
        "print ('frequency more than 20: %d' % len([tokens_count[i] for i in range(0, len(tokens_count))\n",
        "                                                                         if tokens_count[i] > 19]))\n",
        "print ('number of unique characters: %d' % n_unique_token)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a9IP8KQ_5wSA",
        "outputId": "b69b2dc9-b782-47f9-c752-9acc4ca9c9b5"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "median counts: 7 \n",
            "frequency more than 20: 746\n",
            "number of unique characters: 3119\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "a0D6Rmbi6uPh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "index_to_word = [x[0] for x in unique_token]\n",
        "word_to_index = dict([(w,i) for i,w in enumerate(index_to_word)])"
      ],
      "metadata": {
        "id": "FopXHiTn5w8F"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the training data\n",
        "X_train = np.asarray([[word_to_index[w] for w in poem[:-1]] for poem in poems_tokenize])\n",
        "y_train = np.asarray([[word_to_index[w] for w in poem[1:]] for poem in poems_tokenize])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IDsxoyZ53zI3",
        "outputId": "784b555e-fdbc-4769-d983-fbc169220980"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print an training data example\n",
        "x_example, y_example = X_train[17], y_train[17]\n",
        "print (\"x:\\n%s\\n%s\" % (\" \".join([index_to_word[x] for x in x_example]), x_example))\n",
        "print (\"\\ny:\\n%s\\n%s\" % (\" \".join([index_to_word[x] for x in y_example]), y_example))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3f0Nsz-w8Y8m",
        "outputId": "fa8a7f1e-9a4f-4aca-c05a-b18d8ddda617"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x:\n",
            "南 有 樛 木 ， 葛 藟 萦 之 。 乐 只 君 子 ， 福 履 成 之\n",
            "[313, 1134, 1251, 1143, 3115, 2212, 2267, 2204, 43, 8, 46, 354, 375, 603, 3115, 1768, 696, 929, 43]\n",
            "\n",
            "y:\n",
            "有 樛 木 ， 葛 藟 萦 之 。 乐 只 君 子 ， 福 履 成 之 。\n",
            "[1134, 1251, 1143, 3115, 2212, 2267, 2204, 43, 8, 46, 354, 375, 603, 3115, 1768, 696, 929, 43, 8]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save training data\n",
        "pickle.dump((X_train, y_train, index_to_word, word_to_index), open('Shi_trainingData.pkl', 'wb'))"
      ],
      "metadata": {
        "id": "nStnnpj48gx1"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models        import Sequential\n",
        "from keras.layers        import Input, Dense, Dropout\n",
        "from keras.layers        import Embedding\n",
        "from keras.layers        import LSTM\n",
        "from keras               import backend as K\n",
        "from keras.preprocessing import sequence\n",
        "import tensorflow as tf\n",
        "\n",
        "import pickle\n",
        "import numpy      as np"
      ],
      "metadata": {
        "id": "EgP3-tI58mz1"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_cores = 3\n",
        "num_CPU = 8\n",
        "num_GPU = 0\n",
        "config = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=num_cores,\\\n",
        "        inter_op_parallelism_threads=num_cores, allow_soft_placement=True,\\\n",
        "        device_count = {'CPU' : num_CPU, 'GPU' : num_GPU})\n",
        "sess = tf.compat.v1.Session(config=config)\n",
        "K.set_session(sess)"
      ],
      "metadata": {
        "id": "JvezgfRf9NzW"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.python.client import device_lib\n",
        "print(device_lib.list_local_devices())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e6W-1m1q9Qz8",
        "outputId": "6bbab5cb-5c4a-4f82-e86f-74ec705f23c6"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[name: \"/device:CPU:0\"\n",
            "device_type: \"CPU\"\n",
            "memory_limit: 268435456\n",
            "locality {\n",
            "}\n",
            "incarnation: 10462040029938473289\n",
            "xla_global_id: -1\n",
            "]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "latent_dim = 1024"
      ],
      "metadata": {
        "id": "eP29Re9vCr7O"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, y_train, index_to_word, word_to_index = pickle.load(open('Shi_trainingData.pkl', 'rb'))"
      ],
      "metadata": {
        "id": "IX3EqI2HCu8Q"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('X_train shape: {}, Y_train shape: {}'.format(X_train.shape, y_train.shape))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-XD8yczuCw8n",
        "outputId": "1aec3eff-52e7-483d-8ff2-8921dfa7e5be"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train shape: (3251,), Y_train shape: (3251,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train[0])\n",
        "print(y_train[0])\n",
        "print(index_to_word[0:10])\n",
        "print(list(word_to_index.keys())[0:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SX68bGxZCy7G",
        "outputId": "bf4359c2-eb55-4ce9-fabf-13ba4801a21d"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[214, 214, 2835, 3056, 3115, 475, 1340, 43, 1371, 8, 1816, 1818, 1409, 562, 3115, 375, 603, 563, 2642]\n",
            "[214, 2835, 3056, 3115, 475, 1340, 43, 1371, 8, 1816, 1818, 1409, 562, 3115, 375, 603, 563, 2642, 8]\n",
            "[' ', '!', '/', '>', '?', 'd', 't', '□', '。', '《']\n",
            "[' ', '!', '/', '>', '?', 'd', 't', '□', '。', '《']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_characters = sorted(list(word_to_index))\n",
        "target_characters = sorted(list(word_to_index))\n",
        "num_encoder_tokens = len(input_characters)\n",
        "num_decoder_tokens = len(target_characters)\n",
        "max_encoder_seq_length = max([len(txt) for txt in X_train])\n",
        "max_decoder_seq_length = max([len(txt) for txt in y_train])\n",
        "\n",
        "print('Number of samples:', len(X_train))\n",
        "print('Number of unique input tokens:', num_encoder_tokens)\n",
        "print('Number of unique output tokens:', num_decoder_tokens)\n",
        "print('Max sequence length for inputs:', max_encoder_seq_length)\n",
        "print('Max sequence length for outputs:', max_decoder_seq_length)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u0XjEIUGC1SC",
        "outputId": "a212b6b7-fddb-44c7-8ae1-90dd6678070d"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of samples: 3251\n",
            "Number of unique input tokens: 3119\n",
            "Number of unique output tokens: 3119\n",
            "Max sequence length for inputs: 125\n",
            "Max sequence length for outputs: 125\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.callbacks import LambdaCallback\n",
        "from keras.models        import Sequential\n",
        "from keras.layers        import Input, Dense, Dropout\n",
        "from keras.layers        import Embedding\n",
        "from keras.layers        import LSTM\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from keras               import backend as K\n",
        "from keras.preprocessing import sequence\n",
        "\n",
        "import random"
      ],
      "metadata": {
        "id": "bGlc76TsC-iB"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# build the model: a single LSTM\n",
        "print('Build model...')\n",
        "model = Sequential()\n",
        "maxlen =1000\n",
        "model.add(LSTM(128, input_shape=(maxlen, len(input_characters))))\n",
        "model.add(Dense(len(input_characters), activation='relu'))\n",
        "\n",
        "optimizer = RMSprop(lr=0.01)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=optimizer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rID1jVEWDAue",
        "outputId": "394582c1-5f70-489f-b263-dcf5942dd751"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Build model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/rmsprop.py:130: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(RMSprop, self).__init__(name, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gKQzT221DQAF",
        "outputId": "eadd5e0b-bbfd-4581-cca4-46535f7f5f00"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm (LSTM)                 (None, 128)               1662976   \n",
            "                                                                 \n",
            " dense (Dense)               (None, 3119)              402351    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,065,327\n",
            "Trainable params: 2,065,327\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras.callbacks import LambdaCallback\n",
        "from keras.models        import Sequential\n",
        "from keras.layers        import Input, Dense, Dropout\n",
        "from keras.layers        import Embedding\n",
        "from keras.layers        import LSTM\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from keras               import backend as K\n",
        "from keras.preprocessing import sequence\n",
        "import tensorflow as tf\n",
        "\n",
        "import random\n",
        "import pickle\n",
        "import numpy      as np"
      ],
      "metadata": {
        "id": "FdgeXFK6EBjZ"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "maxlen = 31\n",
        "batch_size = 256"
      ],
      "metadata": {
        "id": "bzNFiqY3EFJH"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# After load data\n",
        "class DataGenerator(keras.utils.all_utils.Sequence):\n",
        "    \"\"\"Generates data for Keras.\"\"\"\n",
        "    def __init__(self, X_train=X_train, y_train=y_train, maxlen=maxlen, n_classes=len(input_characters), shuffle=True, \n",
        "                batch_size=batch_size):\n",
        "        \"\"\"Initialization.\n",
        "        \n",
        "        Args:\n",
        "        \"\"\"\n",
        "        self.X_train = X_train\n",
        "        self.y_train = y_train\n",
        "        self.maxlen = maxlen\n",
        "        self.n_classes = n_classes\n",
        "        self.shuffle = shuffle\n",
        "        self.batch_size = batch_size\n",
        "        self.on_epoch_end()\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"Denotes the number of batches per epoch.\"\"\"\n",
        "        return int(np.floor(len(self.X_train) / self.batch_size))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        \"\"\"Generate one batch of data.\"\"\"\n",
        "        # Randomly sample a sentence length\n",
        "        sentence_length = np.random.randint(self.maxlen - 1) + 1  # Guarantee pick at least 1 word\n",
        "        \n",
        "        x = []\n",
        "        y = []\n",
        "        for n in range(self.batch_size):\n",
        "            # Randomly sample a poem\n",
        "            poem_id = np.random.randint(len(self.X_train))\n",
        "            poem = self.X_train[poem_id]\n",
        "            \n",
        "            # Create sentence and next_char\n",
        "            sentence = poem[0:sentence_length]\n",
        "            \n",
        "            # Vectorize\n",
        "            x_temp = np.zeros((sentence_length, self.n_classes))\n",
        "            y_temp = np.zeros(self.n_classes)\n",
        "            for t, char in enumerate(sentence):\n",
        "                x_temp[t, char] = 1\n",
        "            if len(self.y_train[poem_id]) >= sentence_length:\n",
        "                y_temp[self.y_train[poem_id][sentence_length - 1]] = 1\n",
        "            else:\n",
        "                y_temp[5] = 1  # Mark as \".\"\n",
        "            x.append(x_temp)\n",
        "            y.append(y_temp)\n",
        "        \n",
        "        X = np.array(x, dtype=np.bool)\n",
        "        y = np.array(y, dtype=np.bool)\n",
        "        return X, y\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        \"\"\"Updates indexes after each epoch.\"\"\"\n",
        "        # self.indexes = np.arange(len(self.img_files))\n",
        "        # if self.shuffle == True:\n",
        "        #    np.random.shuffle(self.indexes)\n",
        "        pass\n",
        "    \n",
        "train_datagen = DataGenerator()"
      ],
      "metadata": {
        "id": "HYUX2bQgELau"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# build the model: a single LSTM\n",
        "print('Build model...')\n",
        "model2 = Sequential()\n",
        "model2.add(LSTM(256, input_shape=(None, len(input_characters))))\n",
        "model2.add(Dense(len(input_characters), activation='softplus'))\n",
        "\n",
        "optimizer = RMSprop(learning_rate=0.05)\n",
        "model2.compile(loss='categorical_crossentropy', optimizer=optimizer)\n",
        "\n",
        "print(model2.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FqIcxF_KEOoY",
        "outputId": "1472e876-4986-4893-8870-91a2fefb4a2a"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Build model...\n",
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_2 (LSTM)               (None, 256)               3457024   \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 3119)              801583    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,258,607\n",
            "Trainable params: 4,258,607\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def sample(preds, temperature=1.5):\n",
        "    # helper function to sample an index from a probability array\n",
        "    preds = np.asarray(preds).astype('float64')\n",
        "    preds = np.log(preds) / temperature\n",
        "    exp_preds = np.exp(preds)\n",
        "    preds = exp_preds / np.sum(exp_preds)\n",
        "    probas = np.random.multinomial(1, preds, 1)\n",
        "    return np.argmax(probas)\n",
        "\n",
        "def on_epoch_end2(epoch, _, input_sentence=\"诗起\", temperature=1.3, maxlen=30):\n",
        "    # Function invoked at end of each epoch. Prints generated text.\n",
        "    # Recurrent for maxlen\n",
        "    cur_len = len(input_sentence)\n",
        "\n",
        "    # Initiate\n",
        "    input_x_index = [word_to_index[i] for i in input_sentence]\n",
        "    input_x = np.zeros((1, maxlen, len(input_characters)))\n",
        "    for i, index in enumerate(input_x_index):\n",
        "        input_x[0, i, index] = 1\n",
        "\n",
        "    while cur_len < maxlen:\n",
        "        preds = model2.predict(input_x[:, 0:cur_len, :], verbose=0)[0]\n",
        "        next_index = sample(preds, temperature)\n",
        "        next_char = index_to_word[next_index]\n",
        "        input_sentence += next_char\n",
        "        input_x[0, cur_len, next_index] = 1\n",
        "        cur_len += 1\n",
        "        \n",
        "    print(\"Epoch {}, output: {}\".format(epoch, input_sentence))\n",
        "\n",
        "print_callback = LambdaCallback(on_epoch_end=on_epoch_end2)\n",
        "\n",
        "# model2.fit(x, y,\n",
        "#           batch_size=128,\n",
        "#           epochs=1,\n",
        "#           callbacks=[print_callback])\n",
        "model2.fit_generator(train_datagen, epochs=80, use_multiprocessing=True, verbose=1, \n",
        "                    callbacks=[print_callback])\n",
        "\n",
        "# model2.save(\"40_words.h5\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fcet2gDLEcWC",
        "outputId": "8f5cf85d-f361-4865-ffd6-176f2a81381f"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/80\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:38: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:50: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12/12 [==============================] - ETA: 0s - loss: 8.6508Epoch 0, output: 诗起既监寐。蹻象象此谗维，潝來尸或衣內吠维，施旅或洒以万拚田\n",
            "12/12 [==============================] - 22s 2s/step - loss: 8.6508\n",
            "Epoch 2/80\n",
            "12/12 [==============================] - ETA: 0s - loss: 5.9655Epoch 1, output: 诗起。言d飘复君彼止厥厥d。渝为维d氏帝dd寘畛谷岁泮音民d\n",
            "12/12 [==============================] - 29s 3s/step - loss: 5.9655\n",
            "Epoch 3/80\n",
            "12/12 [==============================] - ETA: 0s - loss: 6.0916Epoch 2, output: 诗起不人。时无中簫陶政不，瞻行其王以车于？野附子兮幽言独宇誰\n",
            "12/12 [==============================] - 26s 2s/step - loss: 6.0916\n",
            "Epoch 4/80\n",
            "12/12 [==============================] - ETA: 0s - loss: 7.0530Epoch 3, output: 诗起，岡黄。養褎荏鷺以火成晛告三崇逝幅输。倒达d活，也归晛畯\n",
            "12/12 [==============================] - 16s 1s/step - loss: 7.0530\n",
            "Epoch 5/80\n",
            "12/12 [==============================] - ETA: 0s - loss: 7.2438Epoch 4, output: 诗起朋劳振武有参文繁。皇夫人我以以林瘁茀d已嘉子彼戾皇dd？\n",
            "12/12 [==============================] - 20s 2s/step - loss: 7.2438\n",
            "Epoch 6/80\n",
            "12/12 [==============================] - ETA: 0s - loss: 6.9002Epoch 5, output: 诗起懿如彼虞今有漘胥何興，由哀d。。秣心我活为周以dd？奥，\n",
            "12/12 [==============================] - 23s 2s/step - loss: 6.9002\n",
            "Epoch 7/80\n",
            "12/12 [==============================] - ETA: 0s - loss: 5.7542Epoch 6, output: 诗起匪万。独矣长艾哉叔歌帝群遂孙d，行d鞠昊胡之有属周仪蠃至\n",
            "12/12 [==============================] - 23s 2s/step - loss: 5.7542\n",
            "Epoch 8/80\n",
            "12/12 [==============================] - ETA: 0s - loss: 6.0571Epoch 7, output: 诗起年上配迎小国。国方思荼敢遹殷兮四虞哙穆夜仲乐祿梦三入，來\n",
            "12/12 [==============================] - 25s 2s/step - loss: 6.0571\n",
            "Epoch 9/80\n",
            "12/12 [==============================] - ETA: 0s - loss: 5.7788Epoch 8, output: 诗起之辟民斯訩兄麦驛多斯蹙从胥平不取疾转孙d賚d六厥自縱。d\n",
            "12/12 [==============================] - 19s 1s/step - loss: 5.7788\n",
            "Epoch 10/80\n",
            "12/12 [==============================] - ETA: 0s - loss: 5.8770Epoch 9, output: 诗起露宅荒d人孙曰喬发。茂位翼歆我臧d莫矣心晤。賚斯王止。为\n",
            "12/12 [==============================] - 21s 2s/step - loss: 5.8770\n",
            "Epoch 11/80\n",
            "12/12 [==============================] - ETA: 0s - loss: 5.9036Epoch 10, output: 诗起彼d矣无明商也式或酒有我其營瑟dd。邦命长如速我伊功。其\n",
            "12/12 [==============================] - 20s 2s/step - loss: 5.9036\n",
            "Epoch 12/80\n",
            "12/12 [==============================] - ETA: 0s - loss: 5.5959Epoch 11, output: 诗起自毋乐劬夫于周之枝予各发d似薪近葭d食无蝣其粲之蓺在维虹\n",
            "12/12 [==============================] - 23s 2s/step - loss: 5.5959\n",
            "Epoch 13/80\n",
            "12/12 [==============================] - ETA: 0s - loss: 5.4858Epoch 12, output: 诗起维雄归。祉d叶无尹三汾玉跋弗嗟今式威罔月侯仍兮d白而鸟去\n",
            "12/12 [==============================] - 17s 1s/step - loss: 5.4858\n",
            "Epoch 14/80\n",
            "12/12 [==============================] - ETA: 0s - loss: 4.8130Epoch 13, output: 诗起南沙予d是茹士其予原君子d忧醉休d藹方不止，硕事涂配。孝\n",
            "12/12 [==============================] - 23s 2s/step - loss: 4.8130\n",
            "Epoch 15/80\n",
            "12/12 [==============================] - ETA: 0s - loss: 4.1835Epoch 14, output: 诗起？千，视心天宿，耻弟多館！关朱伊沸d天家d天兮ddddd\n",
            "12/12 [==============================] - 25s 2s/step - loss: 4.1835\n",
            "Epoch 16/80\n",
            "12/12 [==============================] - ETA: 0s - loss: 5.1174Epoch 15, output: 诗起一之何维柏戾。入悠华有醉，其不稷叟疾归。夫交百豆。；暴维\n",
            "12/12 [==============================] - 18s 1s/step - loss: 5.1174\n",
            "Epoch 17/80\n",
            "12/12 [==============================] - ETA: 0s - loss: 3.9896Epoch 16, output: 诗起伊弃ddd于岁d乐，无背。或侯发亦是。不匪孽天dd式不箕\n",
            "12/12 [==============================] - 22s 2s/step - loss: 3.9896\n",
            "Epoch 18/80\n",
            "12/12 [==============================] - ETA: 0s - loss: 4.2672Epoch 17, output: 诗起。征彼清天人福式隕。聞之儦哉矣。翼師既矣。言适百栈三有撥\n",
            "12/12 [==============================] - 21s 2s/step - loss: 4.2672\n",
            "Epoch 19/80\n",
            "12/12 [==============================] - ETA: 0s - loss: 5.1322Epoch 18, output: 诗起。菽依则祈矣？稼飲天昭棘实见不民子，俾锦俾华王驈。蝇鼓无\n",
            "12/12 [==============================] - 18s 1s/step - loss: 5.1322\n",
            "Epoch 20/80\n",
            "12/12 [==============================] - ETA: 0s - loss: 3.6508Epoch 19, output: 诗起几央，克 克舌。清天周蔓，蔽何旨穀在d士也我？视彼寿泮矣\n",
            "12/12 [==============================] - 21s 2s/step - loss: 3.6508\n",
            "Epoch 21/80\n",
            "12/12 [==============================] - ETA: 0s - loss: 3.4857Epoch 20, output: 诗起畟完。邑履鸣丰。崇寝之民，月其虔：d白。挹彼淮人，何稼祖\n",
            "12/12 [==============================] - 20s 2s/step - loss: 3.4857\n",
            "Epoch 22/80\n",
            "12/12 [==============================] - ETA: 0s - loss: 3.6052Epoch 21, output: 诗起楚濯辟，盖号不禄。克处。螣甫优土！女旄臨罔。求晛降豈，君\n",
            "12/12 [==============================] - 20s 2s/step - loss: 3.6052\n",
            "Epoch 23/80\n",
            "12/12 [==============================] - ETA: 0s - loss: 3.5982Epoch 22, output: 诗起驪方跄；觏露君子，厥犧四国就謀吹哀。芹思烈矣，老鋪西龟归\n",
            "12/12 [==============================] - 22s 2s/step - loss: 3.5982\n",
            "Epoch 24/80\n",
            "12/12 [==============================] - ETA: 0s - loss: 3.9870Epoch 23, output: 诗起烝豫告颓，穡写兮。我发君子，亶鼓先禮，序其岁衣翼周。況事\n",
            "12/12 [==============================] - 24s 2s/step - loss: 3.9870\n",
            "Epoch 25/80\n",
            "12/12 [==============================] - ETA: 0s - loss: 2.7014Epoch 24, output: 诗起靡，何潀匪声。在山之湜，在在师業。虔唁靡依，或栖或？楚，\n",
            "12/12 [==============================] - 23s 2s/step - loss: 2.7014\n",
            "Epoch 26/80\n",
            "12/12 [==============================] - ETA: 0s - loss: 3.5638Epoch 25, output: 诗起是鼠衣相奔云d剪既閑。维乐臣彼松云胥之卜。孙山之跄泥d其\n",
            "12/12 [==============================] - 20s 2s/step - loss: 3.5638\n",
            "Epoch 27/80\n",
            "12/12 [==============================] - ETA: 0s - loss: 2.7227Epoch 26, output: 诗起褧河，滌啄俾覯哉。长車既勇，於士骄处。其莺父，則厲言謝，\n",
            "12/12 [==============================] - 22s 2s/step - loss: 2.7227\n",
            "Epoch 28/80\n",
            "12/12 [==============================] - ETA: 0s - loss: 3.3828Epoch 27, output: 诗起南翼。自北成，勿祃保礼。如伊不风，公可言来。。三事匪耳，\n",
            "12/12 [==============================] - 24s 2s/step - loss: 3.3828\n",
            "Epoch 29/80\n",
            "12/12 [==============================] - ETA: 0s - loss: 3.6440Epoch 28, output: 诗起用銶，场乱佩福。覆背矣皇，奕人有阜。日昊人穀，何神不关，\n",
            "12/12 [==============================] - 23s 2s/step - loss: 3.6440\n",
            "Epoch 30/80\n",
            "12/12 [==============================] - ETA: 0s - loss: 3.0420Epoch 29, output: 诗起女，各饮烈式；外山居莫。式穀怓宮，肇定戎常，兄弟莫濯而，\n",
            "12/12 [==============================] - 19s 2s/step - loss: 3.0420\n",
            "Epoch 31/80\n",
            "12/12 [==============================] - ETA: 0s - loss: 3.5013Epoch 30, output: 诗起昌陰偃孔鼓山。豈弟君子？子之佩之。d公尸遠，薄言采兮。可\n",
            "12/12 [==============================] - 21s 2s/step - loss: 3.5013\n",
            "Epoch 32/80\n",
            "12/12 [==============================] - ETA: 0s - loss: 3.7620Epoch 31, output: 诗起敷道上先俾世有小缺谈知，有多風螫；民各我东。既典有膴人岡\n",
            "12/12 [==============================] - 20s 2s/step - loss: 3.7620\n",
            "Epoch 33/80\n",
            "12/12 [==============================] - ETA: 0s - loss: 2.9543Epoch 32, output: 诗起有救，雨雪载敖，寧不南，克保尔忒，饮我言自取，鷺于乃赫d\n",
            "12/12 [==============================] - 21s 2s/step - loss: 2.9543\n",
            "Epoch 34/80\n",
            "12/12 [==============================] - ETA: 0s - loss: 2.8054Epoch 33, output: 诗起自彧孔乐。烝曰云孔哉兄d从ddddddddddddddd\n",
            "12/12 [==============================] - 21s 2s/step - loss: 2.8054\n",
            "Epoch 35/80\n",
            "12/12 [==============================] - ETA: 0s - loss: 2.5048Epoch 34, output: 诗起百极。仲可渭往，尊覆役道。兴人以車，黍稷采卬。鲁衣有威，\n",
            "12/12 [==============================] - 25s 2s/step - loss: 2.5048\n",
            "Epoch 36/80\n",
            "12/12 [==============================] - ETA: 0s - loss: 3.1982Epoch 35, output: 诗起蓫征夫d丘生d匪dddddddddddddddddddd\n",
            "12/12 [==============================] - 18s 1s/step - loss: 3.1982\n",
            "Epoch 37/80\n",
            "12/12 [==============================] - ETA: 0s - loss: 3.2750Epoch 36, output: 诗起命扬子之霆，德音不可令履。靖酒既居师百言；谷嗜登杲，将?\n",
            "12/12 [==============================] - 20s 1s/step - loss: 3.2750\n",
            "Epoch 38/80\n",
            "12/12 [==============================] - ETA: 0s - loss: 2.8911Epoch 37, output: 诗起多。河民遗洋。月歲序屦。不采其采薇，绿d髦有。；武王悠哉\n",
            "12/12 [==============================] - 23s 2s/step - loss: 2.8911\n",
            "Epoch 39/80\n",
            "12/12 [==============================] - ETA: 0s - loss: 2.4031Epoch 38, output: 诗起止，降而伐孚。神父之故，曷弭予禾月作作ddddddddd\n",
            "12/12 [==============================] - 20s 2s/step - loss: 2.4031\n",
            "Epoch 40/80\n",
            "12/12 [==============================] - ETA: 0s - loss: 2.5741Epoch 39, output: 诗起簋祀，自南采光。召彼迟諄。赫赫厥心。嗟嗟。三畯右止。未將\n",
            "12/12 [==============================] - 24s 2s/step - loss: 2.5741\n",
            "Epoch 41/80\n",
            "12/12 [==============================] - ETA: 0s - loss: 2.3110Epoch 40, output: 诗起孔d，克所厥苌。周蕘采旆，斯灌百羽。人！客侯禋，我几孔极\n",
            "12/12 [==============================] - 24s 2s/step - loss: 2.3110\n",
            "Epoch 42/80\n",
            "12/12 [==============================] - ETA: 0s - loss: 2.8715Epoch 41, output: 诗起武牡驰为阶。践反缺雍苦，忘我憂我士。。思其余，彼其徂矣。\n",
            "12/12 [==============================] - 18s 1s/step - loss: 2.8715\n",
            "Epoch 43/80\n",
            "12/12 [==============================] - ETA: 0s - loss: 2.7715Epoch 42, output: 诗起维可生夕。众维鱼依，见靜时均。柔牡畀言忘。相仲允角，齐侯\n",
            "12/12 [==============================] - 18s 1s/step - loss: 2.7715\n",
            "Epoch 44/80\n",
            "12/12 [==============================] - ETA: 0s - loss: 2.9559Epoch 43, output: 诗起曰秉臣伾dddddddddddddddddddddddd\n",
            "12/12 [==============================] - 17s 1s/step - loss: 2.9559\n",
            "Epoch 45/80\n",
            "12/12 [==============================] - ETA: 0s - loss: 2.5117Epoch 44, output: 诗起烝公，笑其户邦？君子攸芋，两膺柔齐甸，倉方攸尋。王孙何酒\n",
            "12/12 [==============================] - 22s 2s/step - loss: 2.5117\n",
            "Epoch 46/80\n",
            "12/12 [==============================] - ETA: 0s - loss: 2.6109Epoch 45, output: 诗起武王，小子反之。不见其逸，此无恫。商祀厥林，曷用厥女。王\n",
            "12/12 [==============================] - 16s 1s/step - loss: 2.6109\n",
            "Epoch 47/80\n",
            "12/12 [==============================] - ETA: 0s - loss: 3.1638Epoch 46, output: 诗起殽禄之草。深英及姜室。大伊岸。肃肃于偕，民受土征。年。好\n",
            "12/12 [==============================] - 17s 1s/step - loss: 3.1638\n",
            "Epoch 48/80\n",
            "12/12 [==============================] - ETA: 0s - loss: 2.3907Epoch 47, output: 诗起申天，予道有業。岂不震不离?率御言止。维？競縱瞍御，黃发\n",
            "12/12 [==============================] - 21s 2s/step - loss: 2.3907\n",
            "Epoch 49/80\n",
            "12/12 [==============================] - ETA: 0s - loss: 2.4794Epoch 48, output: 诗起近之，滸委咨郭。克大士民，我師则害，親炰雨人。潜式是鸣，\n",
            "12/12 [==============================] - 18s 2s/step - loss: 2.4794\n",
            "Epoch 50/80\n",
            "12/12 [==============================] - ETA: 0s - loss: 2.6663Epoch 49, output: 诗起雨，烈假不苍，民亦有耄。隕彼厚我，有切皇离。素衣翱枣，孔\n",
            "12/12 [==============================] - 18s 2s/step - loss: 2.6663\n",
            "Epoch 51/80\n",
            "12/12 [==============================] - ETA: 0s - loss: 2.6150Epoch 50, output: 诗起烈震來保侯dd尔有覆dddddddddddddddddd\n",
            "12/12 [==============================] - 23s 2s/step - loss: 2.6150\n",
            "Epoch 52/80\n",
            "12/12 [==============================] - ETA: 0s - loss: 2.4119Epoch 51, output: 诗起子无民。涼曰不士，舍矢；陂，实于辔如乐兮，曾是宿信。王師\n",
            "12/12 [==============================] - 27s 2s/step - loss: 2.4119\n",
            "Epoch 53/80\n",
            "12/12 [==============================] - ETA: 0s - loss: 1.9629Epoch 52, output: 诗起为期，醉而夭草，韓侯取妻。念我国厉，孝硕不意。歌以望服，\n",
            "12/12 [==============================] - 23s 2s/step - loss: 1.9629\n",
            "Epoch 54/80\n",
            "12/12 [==============================] - ETA: 0s - loss: 2.0329Epoch 53, output: 诗起不識。天维穀攸翩。麦于惠澤人，肅惨惨劬。自则劳旋！城何渭\n",
            "12/12 [==============================] - 21s 2s/step - loss: 2.0329\n",
            "Epoch 55/80\n",
            "12/12 [==============================] - ETA: 0s - loss: 2.3124Epoch 54, output: 诗起厥薇，至于謝及。婉者緌之，敷为城服。岂不生者，泉我不然羜\n",
            "12/12 [==============================] - 17s 1s/step - loss: 2.3124\n",
            "Epoch 56/80\n",
            "12/12 [==============================] - ETA: 0s - loss: 2.2096Epoch 55, output: 诗起蹈其多辰d五可和，八方攸除。行归谋处。不不美，矜明。歌，\n",
            "12/12 [==============================] - 21s 2s/step - loss: 2.2096\n",
            "Epoch 57/80\n",
            "12/12 [==============================] - ETA: 0s - loss: 2.0749Epoch 56, output: 诗起四方，夏兮烝！允；淇不亨谷，弗躬弗何，爰兄之所雨？赫祀百\n",
            "12/12 [==============================] - 20s 2s/step - loss: 2.0749\n",
            "Epoch 58/80\n",
            "12/12 [==============================] - ETA: 0s - loss: 2.5195Epoch 57, output: 诗起佩相。角流茹言：，祀则为忒也彼受之柞，可以作烝穀君。乃倉\n",
            "12/12 [==============================] - 19s 2s/step - loss: 2.5195\n",
            "Epoch 59/80\n",
            "12/12 [==============================] - ETA: 0s - loss: 2.2635Epoch 58, output: 诗起庶茀，四方为岳。无有後士。宣岐之滨，逢天维穀。寺予永叹，\n",
            "12/12 [==============================] - 21s 2s/step - loss: 2.2635\n",
            "Epoch 60/80\n",
            "12/12 [==============================] - ETA: 0s - loss: 2.5235Epoch 59, output: 诗起d萋，則不可成。行贯士方，不谭礼一疆dddddddddd\n",
            "12/12 [==============================] - 21s 2s/step - loss: 2.5235\n",
            "Epoch 61/80\n",
            "12/12 [==============================] - ETA: 0s - loss: 2.0196Epoch 60, output: 诗起既多。既嗟万角，既六生，。或王事靡于。匪毕。荏假殷取，燔\n",
            "12/12 [==============================] - 23s 2s/step - loss: 2.0196\n",
            "Epoch 62/80\n",
            "12/12 [==============================] - ETA: 0s - loss: 2.2527Epoch 61, output: 诗起予介德，永大則之。設人报怀，牛彼从同，于为斁。旱伯相矣，\n",
            "12/12 [==============================] - 21s 2s/step - loss: 2.2527\n",
            "Epoch 63/80\n",
            "12/12 [==============================] - ETA: 0s - loss: 3.0161Epoch 62, output: 诗起爰侯止，裳裳之流山。泉競既庶，文维鸟晤，執予硕囿，莫或言\n",
            "12/12 [==============================] - 18s 1s/step - loss: 3.0161\n",
            "Epoch 64/80\n",
            "12/12 [==============================] - ETA: 0s - loss: 2.2471Epoch 63, output: 诗起如式！式勿者展，以矢肅秩。彼京奮不念不知，作成道阻；蕨月\n",
            "12/12 [==============================] - 19s 1s/step - loss: 2.2471\n",
            "Epoch 65/80\n",
            "12/12 [==============================] - ETA: 0s - loss: 2.3355Epoch 64, output: 诗起艾天菽。肇禋祀命以死之此棘，自彼商王母。未见君子，踽有禹\n",
            "12/12 [==============================] - 19s 1s/step - loss: 2.3355\n",
            "Epoch 66/80\n",
            "12/12 [==============================] - ETA: 0s - loss: 2.1307Epoch 65, output: 诗起天子。定申祿。神此由盈，载忌申也。繩建揭莫斯賚须dddd\n",
            "12/12 [==============================] - 17s 1s/step - loss: 2.1307\n",
            "Epoch 67/80\n",
            "12/12 [==============================] - ETA: 0s - loss: 1.8012Epoch 66, output: 诗起为汉，实役明。鼛方式，四天百川。申伯舉民如可鴥上業，为予\n",
            "12/12 [==============================] - 21s 2s/step - loss: 1.8012\n",
            "Epoch 68/80\n",
            "12/12 [==============================] - ETA: 0s - loss: 1.7564Epoch 67, output: 诗起薦雨，忘我桑也。卜来质遠，场衾之光。野有夷亦，式穀一史。\n",
            "12/12 [==============================] - 28s 2s/step - loss: 1.7564\n",
            "Epoch 69/80\n",
            "12/12 [==============================] - ETA: 0s - loss: 2.2547Epoch 68, output: 诗起维何？维天有疾ddddddddddddddddddddd\n",
            "12/12 [==============================] - 24s 2s/step - loss: 2.2547\n",
            "Epoch 70/80\n",
            "12/12 [==============================] - ETA: 0s - loss: 2.4211Epoch 69, output: 诗起，信彼不文王，如坻令烈。以我以我生，來闻且寧，俾尔昌而，\n",
            "12/12 [==============================] - 19s 2s/step - loss: 2.4211\n",
            "Epoch 71/80\n",
            "12/12 [==============================] - ETA: 0s - loss: 1.9048Epoch 70, output: 诗起用嗟?优游长至于怀哉？叔兮何亟车，泄泄，百辟成，礼四予昊\n",
            "12/12 [==============================] - 17s 1s/step - loss: 1.9048\n",
            "Epoch 72/80\n",
            "12/12 [==============================] - ETA: 0s - loss: 2.1308Epoch 71, output: 诗起神烝士武，可以宿。受錫尔共，矢无封王，攸保其福。帝孙不如\n",
            "12/12 [==============================] - 19s 1s/step - loss: 2.1308\n",
            "Epoch 73/80\n",
            "12/12 [==============================] - ETA: 0s - loss: 1.7516Epoch 72, output: 诗起生草。多我武，朝隮其旅。祖皇，度其喈喈。薄言駉者，有驈有\n",
            "12/12 [==============================] - 20s 1s/step - loss: 1.7516\n",
            "Epoch 74/80\n",
            "12/12 [==============================] - ETA: 0s - loss: 2.5359Epoch 73, output: 诗起思哉？维其 矣。北风无惡，。曰归信田！予？心焉。其如正之\n",
            "12/12 [==============================] - 20s 2s/step - loss: 2.5359\n",
            "Epoch 75/80\n",
            "12/12 [==============================] - ETA: 0s - loss: 1.6559Epoch 74, output: 诗起何懿？湛d秩豕之，烝哉！禹淠斯岂。龙旗業公，声闻于南；中\n",
            "12/12 [==============================] - 17s 1s/step - loss: 1.6559\n",
            "Epoch 76/80\n",
            "12/12 [==============================] - ETA: 0s - loss: 1.9523Epoch 75, output: 诗起粲葽，路车及人。于且于位，岂曰不言，还哉不宜。黍离匪楚，\n",
            "12/12 [==============================] - 18s 1s/step - loss: 1.9523\n",
            "Epoch 77/80\n",
            "12/12 [==============================] - ETA: 0s - loss: 1.7077Epoch 76, output: 诗起在京。紀于他人，作百斯郿。先祖于位烈牡靖d，非王茲祖。行\n",
            "12/12 [==============================] - 19s 2s/step - loss: 1.7077\n",
            "Epoch 78/80\n",
            "12/12 [==============================] - ETA: 0s - loss: 2.0474Epoch 77, output: 诗起殷龜涉此锦ddddddddddddddddddddddd\n",
            "12/12 [==============================] - 23s 2s/step - loss: 2.0474\n",
            "Epoch 79/80\n",
            "12/12 [==============================] - ETA: 0s - loss: 1.8716Epoch 78, output: 诗起几饮，女执多饥，謝，实夜在海。大邦有蹶，貳土。群以出民！\n",
            "12/12 [==============================] - 18s 1s/step - loss: 1.8716\n",
            "Epoch 80/80\n",
            "12/12 [==============================] - ETA: 0s - loss: 1.6347Epoch 79, output: 诗起武王烝尝女，六其及厲。振振鷺，鷺于飞时。三归武王，。众湜\n",
            "12/12 [==============================] - 22s 2s/step - loss: 1.6347\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fa4c2579a10>"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "on_epoch_end2(1, _)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f2PThzoaEfw-",
        "outputId": "7ac89a1d-e115-4b5d-b3aa-2b09f5d9eb14"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, output: 诗起在桑，于以异北。衣绣方屋，可以公归息！召錫自，念车。胡转\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "on_epoch_end2(32, _, temperature=1.5, maxlen=50, input_sentence=\"江，\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pK-1bqu7Z95Q",
        "outputId": "3787d9f1-1789-4261-d47e-ac3bd0576b47"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: RuntimeWarning: divide by zero encountered in log\n",
            "  after removing the cwd from sys.path.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 32, output: 江，來卜怛迈。俶载梦亩，保鬵子孙嘉。寿考來宾，或造或揄，。松曰有骏。南衣无疆，二屆时伤。攘其衣裳，夷\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "on_epoch_end2(145, _, temperature=1.2, maxlen=30, input_sentence=\"兰之，幽幽香。\")"
      ],
      "metadata": {
        "id": "BM0sBoMIaSt3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a8ecfaa5-1433-4d5b-88e0-e7309bdd53ff"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: RuntimeWarning: divide by zero encountered in log\n",
            "  after removing the cwd from sys.path.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 145, output: 兰之，幽幽香。。振鷺之楚，克取克晦。维此慎武，雍雍知行，实右\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "on_epoch_end2(124, _, temperature=1.2, maxlen=300, input_sentence=\"今夕是何夕，\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v36hDqkzCAiM",
        "outputId": "eef9e915-68ac-426d-d73b-ac4ea7dd20f3"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: RuntimeWarning: divide by zero encountered in log\n",
            "  after removing the cwd from sys.path.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 124, output: 今夕是何夕，是用大介。。舍曰惮人，予？興迷。皇？音将，云常靡流？谁祸？其作門其？皇王殆止，或钟鼓瑟！d火。无貳无臭，寿而无心。忍予柔仇，武王载京。孝孙孔明，罪罟如获。周池靡止，万寿无弟。神所虽圣，美亡雍，莫莫孔出。谋夫以祖。原隰既骆，震尔如室。执聞多對，松柏仪王。中方是，显夙興夜，雨雪绣之。寇洽之子，其旂不安。无哉尔耳？三姜蛇尔。射则行，小。楚潜居女，具贅卒笑。侯雍，侯方嘉梦。上帝受明，维彼，寿考是豳。母我荓嗟，天子万年。緝涉盖dddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddd\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "BuzAJW_hCaE2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}